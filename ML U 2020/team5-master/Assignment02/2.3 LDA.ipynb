{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Linear Discriminant Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we will work on the Iris data Set. As a little helper for you, we will use an out-of-the-box method from the seaborn package to visualize the data set. The seaborn package is a matplotlib-based visualization package. You can install it by typing the following command in the terminal: \"__sudo pip3 install seaborn__\". If you run the script and you do not see the data, also install the cairo backend with \"__sudo pip3 install cairocffi__\".\n",
    "\n",
    "__Task:__ Which of the four features is the most discriminant one? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T13:54:08.625118Z",
     "start_time": "2020-05-27T13:54:08.619581Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#import seaborn as sns\n",
    "#sns.set()\n",
    "#df = sns.load_dataset(\"iris\")\n",
    "#sns.pairplot(df, hue=\"species\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of a 2-class LDA\n",
    " \n",
    "__Task__: Write a function *train_LDA()* that uses training data $\\mathbf{X}$ and labels $\\mathbf y$ to train an LDA model and returns weights $\\mathbf w$ and a bias $\\mathbf b$ for a two-class problem. Review the lecture slides for the theoretical backgrounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T13:54:08.648611Z",
     "start_time": "2020-05-27T13:54:08.629324Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_lda(X, y):\n",
    "    ''' Train an LDA\n",
    "    Input: X data matrix with shape NxD\n",
    "           y label vector with shape Nx1\n",
    "    Output: weight vector with shape Nx1 \n",
    "            bias term - real-valued '''\n",
    "\n",
    "    # initialisations\n",
    "    mu_c1 = np.mean(X[y==1], 0)\n",
    "    mu_c2 = np.mean(X[y==2], 0)\n",
    "    \n",
    "    cov_c1 = np.cov(X[y==1], rowvar=False)\n",
    "    cov_c2 = np.cov(X[y==2], rowvar=False)\n",
    "    cov_w = 0.5*(cov_c1+cov_c2)\n",
    "    \n",
    "    cov_I = np.linalg.pinv(cov_w, hermitian=True)\n",
    "    \n",
    "    \"Using Fisher's Criterion #2\"\n",
    "    weights = cov_I@(mu_c2 - mu_c1)\n",
    "    bias = -0.5*weights@(mu_c1+mu_c2) \n",
    "    \n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation of the trained LDA model \n",
    "\n",
    "__Task__: Write a function *apply_lda()* that uses the weights and bias of the *train_LDA(X, y)* function and returns a vector of predicted classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T13:54:08.666299Z",
     "start_time": "2020-05-27T13:54:08.651742Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def apply_lda(X_test, weights, bias):\n",
    "    '''Predict the class label per sample \n",
    "    Input: X_test - data matrix with shape NxD\n",
    "           weight vector and bias term from train_LDA\n",
    "    Output: vector with entries 1 or 2 depending on the class'''\n",
    "    \n",
    "    y_hat = weights@X_test.T + bias # = (1,4)(4,35) +1 = (1x35)\n",
    "    temp = []\n",
    "    for _ in y_hat:\n",
    "\n",
    "        if _ >0:\n",
    "            temp.append(2)\n",
    "        else:\n",
    "            temp.append(1)\n",
    "        \n",
    "    return y_test, temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your implementations with the Iris data set\n",
    "\n",
    "In Assignment 1, you have already been inspecting the iris data set. Now, train an LDA on the training data of the iris data set (using only class 1 and 2) and validate it on your training and test data.\n",
    "\n",
    "#### Q2.3.1 Which accuracy can you achieve on the iris data test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T13:54:08.727008Z",
     "start_time": "2020-05-27T13:54:08.690210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy on the test set is 97.14 %\n"
     ]
    }
   ],
   "source": [
    "# Load the iris data set\n",
    "X_train_all = np.loadtxt('data/iris_train.data', delimiter=' ', dtype=float)\n",
    "y_train_all = np.loadtxt('data/iris_train.labels', dtype=int)\n",
    "X_test_all = np.loadtxt('data/iris_test.data', delimiter=' ', dtype=float)\n",
    "y_test_all = np.loadtxt('data/iris_test.labels', dtype=int)\n",
    "\n",
    "# only select classes 1 and 2\n",
    "X_train = X_train_all[np.logical_or(y_train_all == 1, y_train_all == 2)]\n",
    "y_train = y_train_all[np.logical_or(y_train_all == 1, y_train_all == 2)]\n",
    "\n",
    "X_test = X_test_all[np.logical_or(y_test_all == 1, y_test_all == 2)]\n",
    "y_test = y_test_all[np.logical_or(y_test_all == 1, y_test_all == 2)]\n",
    "\n",
    "# train an LDA and apply it on the test data set, report your accuracy (in percent)\n",
    "\n",
    "W, b = train_lda(X_train, y_train)  # train\n",
    "\n",
    "y_hat, y_hat_D = apply_lda(X_test, W, b)  # apply\n",
    "\n",
    "print('The Accuracy on the test set is %.2f %%' %(sum(y_test==y_hat_D)/len(y_test)*100))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 267.059818,
   "position": {
    "height": "40px",
    "left": "700.861px",
    "right": "20px",
    "top": "391.838px",
    "width": "342.06px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
